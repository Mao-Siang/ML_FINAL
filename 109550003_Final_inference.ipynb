{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OqzOHrCMVnV5"
      },
      "source": [
        "## ML Final Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSIwbkVQVtbr"
      },
      "source": [
        "### Import Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCATx3AoJyKK",
        "outputId": "23e20ad2-0ce6-474a-c539-8d5809cd15cc"
      },
      "outputs": [],
      "source": [
        "# For Google Colab\n",
        "# !pip install -q feature-engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bjgIxTWmJv1q"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "from feature_engine.encoding import WoEEncoder\n",
        "from sklearn.impute import KNNImputer\n",
        "import pandas as pd\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9SsUExOVzLM"
      },
      "source": [
        "### Preprocess Functions\n",
        "\n",
        "*   Feature Engineering\n",
        "*   Imputing\n",
        "*   WoE Encoder\n",
        "*   Scaling \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "EMxsI9RWJ3Yc"
      },
      "outputs": [],
      "source": [
        "ref_dict = {\n",
        "    \"A\": [\"measurement_5\", \"measurement_6\", \"measurement_8\"],\n",
        "    \"B\": [\"measurement_4\", \"measurement_5\", \"measurement_7\"],\n",
        "    \"C\": [\"measurement_5\", \"measurement_7\", \"measurement_8\", \"measurement_9\"],\n",
        "    \"D\": [\"measurement_5\", \"measurement_6\", \"measurement_7\", \"measurement_8\"],\n",
        "    \"E\": [\"measurement_4\", \"measurement_5\", \"measurement_6\", \"measurement_8\"],\n",
        "    \"F\": [\"measurement_4\", \"measurement_5\", \"measurement_6\", \"measurement_7\"],\n",
        "    \"G\": [\"measurement_4\", \"measurement_6\", \"measurement_8\", \"measurement_9\"],\n",
        "    \"H\": [\n",
        "        \"measurement_4\",\n",
        "        \"measurement_5\",\n",
        "        \"measurement_7\",\n",
        "        \"measurement_8\",\n",
        "        \"measurement_9\",\n",
        "    ],\n",
        "    \"I\": [\"measurement_3\", \"measurement_7\", \"measurement_8\"],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Xxb5-CQmJ6PN"
      },
      "outputs": [],
      "source": [
        "def preprocess(train, test, features):\n",
        "    data = pd.concat([train, test])\n",
        "    # new features\n",
        "    data[\"m3_missing\"] = data[\"measurement_3\"].isnull().astype(np.int8)\n",
        "    data[\"m5_missing\"] = data[\"measurement_5\"].isnull().astype(np.int8)\n",
        "    data[\"area\"] = data[\"attribute_2\"] * data[\"attribute_3\"]\n",
        "    label = [f\"measurement_{i:d}\" for i in range(3, 17)]\n",
        "    data[\"avg_m3_m16\"] = np.mean(data[label], axis=1)\n",
        "    data[\"std_m3_m16\"] = np.std(data[label], axis=1)\n",
        "    data[\"loading\"] = np.log(data[\"loading\"])\n",
        "    data[\"measurement_2\"].clip(11, None)\n",
        "\n",
        "    for code in data.product_code.unique():\n",
        "        cur_data = data[data.product_code == code]\n",
        "        cur_ref = ref_dict[code]\n",
        "\n",
        "        train_x = cur_data[cur_ref + [\"measurement_17\"]].dropna(how=\"any\")\n",
        "\n",
        "        test_x = cur_data[\n",
        "            (cur_data[cur_ref].isnull().sum(axis=1) == 0)\n",
        "            & (cur_data[\"measurement_17\"].isnull())\n",
        "        ]\n",
        "\n",
        "        model = HuberRegressor(epsilon=1.9)\n",
        "        model.fit(train_x[cur_ref], train_x[\"measurement_17\"])\n",
        "\n",
        "        data.loc[\n",
        "            (data.product_code == code)\n",
        "            & (data[cur_ref].isnull().sum(axis=1) == 0)\n",
        "            & (data[\"measurement_17\"].isnull()),\n",
        "            \"measurement_17\",\n",
        "        ] = model.predict(test_x[cur_ref])\n",
        "\n",
        "        knn = KNNImputer(n_neighbors=3)\n",
        "        data.loc[data.product_code == code, features] = knn.fit_transform(\n",
        "            data.loc[data.product_code == code, features]\n",
        "        )\n",
        "\n",
        "    train = data[data[\"failure\"].notnull()]\n",
        "    test = data[data[\"failure\"].isnull()].drop([\"failure\"], axis=1)\n",
        "\n",
        "    x = train.drop([\"failure\"], axis=1)\n",
        "    y = train[\"failure\"].astype(int)\n",
        "\n",
        "    # use the woe_encoder trained by train_data\n",
        "    woe_encoder = WoEEncoder(variables=[\"attribute_0\"])\n",
        "    woe_encoder.fit(x, y)\n",
        "    x = woe_encoder.transform(x)\n",
        "    test = woe_encoder.transform(test)\n",
        "\n",
        "    return x, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "70vqk5V6J9Zo"
      },
      "outputs": [],
      "source": [
        "def scaling(train, test, features):\n",
        "    scaler = StandardScaler()\n",
        "    scaler.fit(train[features])\n",
        "    scaled_test = scaler.transform(test[features])\n",
        "\n",
        "    # transfer to dataframe\n",
        "    new_test = test.copy()\n",
        "    new_test[features] = scaled_test\n",
        "\n",
        "    assert len(test) == len(new_test)\n",
        "    return new_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Li71jtaMJ_nA"
      },
      "outputs": [],
      "source": [
        "def regression(model, train, test, features):\n",
        "    final_result = np.zeros(len(test))\n",
        "\n",
        "    x_test = scaling(train, test, features)\n",
        "    final_result = model.predict_proba(x_test[features])[:, 1]\n",
        "\n",
        "    return final_result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gg3qAl78V47R"
      },
      "source": [
        "### Predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "e2HoBlAqJold"
      },
      "outputs": [],
      "source": [
        "train = pd.read_csv(\"train/train.csv\")\n",
        "test = pd.read_csv(\"train/test.csv\")\n",
        "features_preprocess = [\n",
        "    feature\n",
        "    for feature in test.columns\n",
        "    if feature.startswith(\"measurement\") or feature == \"loading\"\n",
        "]\n",
        "\n",
        "# Comment this if you don't need the preprocessing\n",
        "# Make sure that there is no invalid data\n",
        "train, test = preprocess(train, test, features_preprocess)\n",
        "result = np.zeros(len(test))\n",
        "\n",
        "feature_used = [\n",
        "    \"loading\",\n",
        "    \"attribute_0\",\n",
        "    \"area\",\n",
        "    \"measurement_17\",\n",
        "    \"m3_missing\",\n",
        "    \"m5_missing\",\n",
        "    \"measurement_0\",\n",
        "    \"measurement_1\",\n",
        "    \"measurement_2\",\n",
        "]\n",
        "\n",
        "models = []\n",
        "# load models\n",
        "for i in range(5):\n",
        "    with open(f\"model/model_{i+1}.pkl\", \"rb\") as f:\n",
        "        models.append(pickle.load(f))\n",
        "# predict the results\n",
        "for model in models:\n",
        "    result += regression(model, train, test, feature_used) / 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gjanuVI3WBlL"
      },
      "source": [
        "### Submission Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "vpgi-DE2WFwx"
      },
      "outputs": [],
      "source": [
        "# write to csv\n",
        "submission = pd.read_csv(\"train/sample_submission.csv\")\n",
        "submission[\"failure\"] = result\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.9 ('ml_final': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "6b6a01ea3d5303728aedcbb75e649a18465ec18acd408dd331b0881511fc70e1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
